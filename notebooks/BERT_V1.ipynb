{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TED Lens BERT V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\envs\\TEDLens\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  With the same humor and humanity he exuded in ...   \n",
       "1  You've never seen data presented like this. Wi...   \n",
       "2  New York Times columnist David Pogue takes aim...   \n",
       "3  In an emotionally charged talk, MacArthur-winn...   \n",
       "4  Sir Ken Robinson makes an entertaining and pro...   \n",
       "\n",
       "                                              topics  \n",
       "0  ['alternative energy', 'cars', 'climate change...  \n",
       "1  ['Africa', 'Asia', 'Google', 'demo', 'economic...  \n",
       "2  ['computers', 'entertainment', 'interface desi...  \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...  \n",
       "4  ['children', 'creativity', 'culture', 'dance',...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./TED_Talks_Dataset/2020-05-01/ted_talks_en.csv')\n",
    "\n",
    "xtraining_column = 'description'\n",
    "useful_data = data[[xtraining_column, 'topics']]\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the Topics available in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3D printing', 'AI', 'AIDS', 'Africa', \"Alzheimer's\", 'Antarctica', 'Anthropocene', 'Asia', 'Audacious Project', 'Autism spectrum disorder', 'Best of the Web', 'Brand', 'Brazil', 'Buddhism', 'CRISPR', 'Christianity', 'DNA', 'Debate', 'Egypt', 'Europe', 'Foreign Policy', 'Gender spectrum', 'God', 'Google', 'HIV', 'Humanities', 'Internet', 'Iran', 'Islam', 'LGBT', 'Latin America', 'MacArthur grant', 'Mars', 'Middle East', 'Moon', 'NASA', 'New York', 'Nobel Prize', 'PTSD', 'Planets', 'Science (hard)', 'Senses', 'Slavery', 'Social Science', 'South America', 'String theory', 'Sun', 'Surgery', 'Syria', 'TED Books', 'TED Connects', 'TED Fellows', 'TED Prize', 'TED Residency', 'TED en Espa√±ol', 'TED-Ed', 'TEDMED', 'TEDNYC', 'TEDYouth', 'TEDx', 'Transgender', 'United States', 'Vaccines', 'activism', 'addiction', 'adventure', 'advertising', 'aging', 'agriculture', 'aircraft', 'algorithm', 'alternative energy', 'ancient world', 'animals', 'animation', 'anthropology', 'ants', 'apes', 'archaeology', 'architecture', 'art', 'arts', 'asteroid', 'astrobiology', 'astronomy', 'atheism', 'augmented reality', 'autism', 'bacteria', 'beauty', 'bees', 'behavioral economics', 'big bang', 'big problems', 'biodiversity', 'bioethics', 'biology', 'biomechanics', 'biomimicry', 'bionics', 'biosphere', 'biotech', 'birds', 'blindness', 'blockchain', 'body language', 'book', 'books', 'botany', 'brain', 'bullying', 'business', 'cancer', 'capitalism', 'cars', 'cello', 'charter for compassion', 'chemistry', 'children', 'china', 'choice', 'cities', 'climate change', 'cloud', 'code', 'cognitive science', 'collaboration', 'comedy', 'communication', 'community', 'compassion', 'complexity', 'composing', 'computers', 'conducting', 'consciousness', 'conservation', 'consumerism', 'cooperation', 'coral reefs', 'coronavirus', 'corruption', 'cosmos', 'creativity', 'crime', 'criminal justice', 'crowdsourcing', 'cryptocurrency', 'culture', 'curiosity', 'dance', 'dark matter', 'data', 'death', 'decision-making', 'deextinction', 'demo', 'democracy', 'depression', 'design', 'development', 'dinosaurs', 'disability', 'disaster relief', 'discovery', 'disease', 'diversity', 'driverless cars', 'drones', 'ebola', 'ecology', 'economics', 'education', 'electricity', 'emotions', 'empathy', 'encryption', 'energy', 'engineering', 'entertainment', 'entrepreneur', 'environment', 'epidemiology', 'evil', 'evolution', 'evolutionary psychology', 'exercise', 'exoskeleton', 'exploration', 'extraterrestrial life', 'extreme sports', 'failure', 'faith', 'family', 'farming', 'fashion', 'fear', 'feminism', 'film', 'finance', 'fish', 'flight', 'food', 'forensics', 'friendship', 'fungi', 'funny', 'future', 'gaming', 'garden', 'gay', 'gender', 'gender equality', 'genetics', 'geology', 'glacier', 'global commons', 'global development', 'global issues', 'goal-setting', 'government', 'grammar', 'graphic design', 'green', 'guitar', 'guns', 'hack', 'happiness', 'health', 'health care', 'healthcare', 'hearing', 'heart health', 'history', 'homelessness', 'human body', 'human origins', 'human rights', 'humanity', 'humor', 'identity', 'illness', 'illusion', 'immigration', 'inclusion', 'india', 'indigenous peoples', 'industrial design', 'inequality', 'infrastructure', 'innovation', 'insects', 'intelligence', 'interface design', 'interview', 'introvert', 'invention', 'investment', 'iraq', 'jazz', 'journalism', 'justice system', 'language', 'law', 'leadership', 'library', 'life', 'literature', 'live music', 'love', 'machine learning', 'magic', 'manufacturing', 'map', 'marine biology', 'marketing', 'markets', 'materials', 'math', 'media', 'medical imaging', 'medical research', 'medicine', 'meditation', 'meme', 'memory', 'men', 'mental health', 'microbes', 'microbiology', 'microfinance', 'microsoft', 'military', 'mind', 'mindfulness', 'mining', 'mission blue', 'mobility', 'molecular biology', 'money', 'monkeys', 'morality', 'motivation', 'movies', 'museums', 'music', 'nanoscale', 'narcotics', 'natural disaster', 'natural resources', 'nature', 'neurology', 'neuroscience', 'news', 'nonviolence', 'novel', 'nuclear energy', 'nuclear weapons', 'obesity', 'oceans', 'oil', 'online video', 'open-source', 'opioids', 'origami', 'pain', 'painting', 'paleontology', 'pandemic', 'parenting', 'peace', 'performance', 'performance art', 'personal growth', 'personality', 'pharmaceuticals', 'philanthropy', 'philosophy', 'photography', 'physics', 'physiology', 'piano', 'plants', 'plastic', 'play', 'poetry', 'policy', 'politics', 'pollution', 'population', 'potential', 'poverty', 'prediction', 'pregnancy', 'presentation', 'primates', 'prison', 'privacy', 'product design', 'productivity', 'programming', 'prosthetics', 'protests', 'psychology', 'public health', 'public spaces', 'quantum physics', 'race', 'rap', 'refugees', 'relationships', 'religion', 'resources', 'rivers', 'robot', 'robots', 'rocket science', 'sanitation', 'science', 'science and art', 'science fiction', 'security', 'self', 'sex', 'sexual violence', 'shopping', 'sight', 'simplicity', 'singer', 'skateboarding', 'sleep', 'smell', 'social change', 'social media', 'society', 'sociology', 'software', 'solar energy', 'solar system', 'sound', 'space', 'speech', 'spoken word', 'sports', 'start-up', 'state-building', 'statistics', 'stigma', 'storytelling', 'street art', 'student', 'submarine', 'success', 'suicide', 'surveillance', 'sustainability', 'synthetic biology', 'teaching', 'technology', 'telecom', 'telescopes', 'television', 'terrorism', 'testing', 'theater', 'time', 'toy', 'trafficking', 'transportation', 'travel', 'trees', 'trust', 'typography', 'universe', 'urban', 'urban planning', 'violence', 'violin', 'virtual reality', 'virus', 'visualizations', 'vocals', 'vulnerability', 'war', 'water', 'weather', 'web', 'wikipedia', 'wind energy', 'women', 'women in business', 'work', 'work-life balance', 'world cultures', 'writing', 'wunderkind', 'youth']\n",
      "457  Topics\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "data = useful_data\n",
    "\n",
    "# converting the text to \n",
    "all_topics = []\n",
    "for topics,i in zip(data['topics'],range(len(data['topics']))):\n",
    "    all_topics+=eval(topics)\n",
    "    data['topics'][i] = eval(topics)\n",
    "\n",
    "unique_topics = sorted(list(set(all_topics)))\n",
    "print(unique_topics)\n",
    "\n",
    "num_labels = len(unique_topics)\n",
    "print(num_labels,' Topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert a DataFrame column to its BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>[alternative energy, cars, climate change, cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>[Africa, Asia, Google, demo, economics, global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>[computers, entertainment, interface design, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>[MacArthur grant, activism, business, cities, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>[children, creativity, culture, dance, educati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  With the same humor and humanity he exuded in ...   \n",
       "1  You've never seen data presented like this. Wi...   \n",
       "2  New York Times columnist David Pogue takes aim...   \n",
       "3  In an emotionally charged talk, MacArthur-winn...   \n",
       "4  Sir Ken Robinson makes an entertaining and pro...   \n",
       "\n",
       "                                              topics  \n",
       "0  [alternative energy, cars, climate change, cul...  \n",
       "1  [Africa, Asia, Google, demo, economics, global...  \n",
       "2  [computers, entertainment, interface design, m...  \n",
       "3  [MacArthur grant, activism, business, cities, ...  \n",
       "4  [children, creativity, culture, dance, educati...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "topics_labels = mlb.fit_transform(data['topics'])\n",
    "\n",
    "for i in range(len(data['topics'])):\n",
    "    data['topics'][i] = topics_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  With the same humor and humanity he exuded in ...   \n",
       "1  You've never seen data presented like this. Wi...   \n",
       "2  New York Times columnist David Pogue takes aim...   \n",
       "3  In an emotionally charged talk, MacArthur-winn...   \n",
       "4  Sir Ken Robinson makes an entertaining and pro...   \n",
       "\n",
       "                                              topics  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_len, new_data=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = df\n",
    "        self.text = df.description\n",
    "        self.new_data = new_data\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        if not new_data:\n",
    "            self.targets = self.data.topics\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(text,None,\n",
    "                                           add_special_tokens=True,\n",
    "                                           max_length=self.max_len,\n",
    "                                           pad_to_max_length=True,\n",
    "                                           return_token_type_ids=True)\n",
    "        out = {\n",
    "            \"input_ids\": torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "        }\n",
    "        if not self.new_data:\n",
    "            out[\"targets\"] = torch.tensor(self.targets[index], dtype=torch.float)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 320\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8 \n",
    "\n",
    "train_df = data.sample(frac=train_size, random_state=42)\n",
    "val_df = data.drop(train_df.index).reset_index(drop=True)\n",
    "train_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)\n",
    "train_set = MultiLabelDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_set = MultiLabelDataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "\n",
    "class DistilBertClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBertClass, self).__init__()\n",
    "        \n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Linear(768, 768),\n",
    "                                             torch.nn.ReLU(),\n",
    "                                             torch.nn.Dropout(0.1),\n",
    "                                             torch.nn.Linear(768, 457))\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        out = hidden_state[:,0]\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on cpu\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertClass()\n",
    "model.to(DEVICE)\n",
    "print(f\"Model on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.functional.binary_cross_entropy_with_logits(outputs,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for _, data in tqdm(enumerate(train_loader)):\n",
    "        input_ids = data['input_ids'].to(DEVICE, dtype=torch.long)\n",
    "        attention_mask = data['attention_mask'].to(DEVICE, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(DEVICE, dtype=torch.long)\n",
    "        targets = data['targets'].to(DEVICE, dtype=torch.float)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        if _ % 5000 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def validate():\n",
    "  model.eval()\n",
    "\n",
    "  fin_targets = []\n",
    "  fin_outputs = []\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for _, data in tqdm(enumerate(val_loader, 0)):\n",
    "      ids = data['input_ids'].to(DEVICE, dtype=torch.long)\n",
    "      mask = data['attention_mask'].to(DEVICE, dtype=torch.long)\n",
    "      token_type_ids = data['token_type_ids'].to(DEVICE, dtype=torch.long)\n",
    "      targets = data['targets'].to(DEVICE, dtype=torch.float)\n",
    "\n",
    "      outputs = model(ids, mask, token_type_ids)\n",
    "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "      \n",
    "  fin_outputs = np.array(fin_outputs) >= 0.5\n",
    "  accuracy = metrics.accuracy_score(fin_targets, fin_outputs)\n",
    "  f1_score_micro = metrics.f1_score(fin_targets, fin_outputs, average='micro')\n",
    "  f1_score_macro = metrics.f1_score(fin_targets, fin_outputs, average='macro') \n",
    "\n",
    "  return {\n",
    "      \"Accuracy Score\": accuracy,\n",
    "      \"F1 score(micro)\": f1_score_micro,\n",
    "      \"F1 score(macro)\": f1_score_macro\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  train(epoch)\n",
    "  print(validate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEDLens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
