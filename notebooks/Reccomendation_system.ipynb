{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightweight Recommendation System with tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                                             topics\n",
       "0        1  ['alternative energy', 'cars', 'climate change...\n",
       "1       92  ['Africa', 'Asia', 'Google', 'demo', 'economic...\n",
       "2        7  ['computers', 'entertainment', 'interface desi...\n",
       "3       53  ['MacArthur grant', 'activism', 'business', 'c...\n",
       "4       66  ['children', 'creativity', 'culture', 'dance',..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ted_talks_en.csv')\n",
    "\n",
    "xtraining_column = 'talk_id'\n",
    "useful_data = data[[xtraining_column, 'topics']]\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_195396\\3093567900.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  useful_data.loc[i]['topics'] = eval(topics)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3D printing', 'AI', 'AIDS', 'Africa', \"Alzheimer's\", 'Antarctica', 'Anthropocene', 'Asia', 'Audacious Project', 'Autism spectrum disorder', 'Best of the Web', 'Brand', 'Brazil', 'Buddhism', 'CRISPR', 'Christianity', 'DNA', 'Debate', 'Egypt', 'Europe', 'Foreign Policy', 'Gender spectrum', 'God', 'Google', 'HIV', 'Humanities', 'Internet', 'Iran', 'Islam', 'LGBT', 'Latin America', 'MacArthur grant', 'Mars', 'Middle East', 'Moon', 'NASA', 'New York', 'Nobel Prize', 'PTSD', 'Planets', 'Science (hard)', 'Senses', 'Slavery', 'Social Science', 'South America', 'String theory', 'Sun', 'Surgery', 'Syria', 'TED Books', 'TED Connects', 'TED Fellows', 'TED Prize', 'TED Residency', 'TED en Español', 'TED-Ed', 'TEDMED', 'TEDNYC', 'TEDYouth', 'TEDx', 'Transgender', 'United States', 'Vaccines', 'activism', 'addiction', 'adventure', 'advertising', 'aging', 'agriculture', 'aircraft', 'algorithm', 'alternative energy', 'ancient world', 'animals', 'animation', 'anthropology', 'ants', 'apes', 'archaeology', 'architecture', 'art', 'arts', 'asteroid', 'astrobiology', 'astronomy', 'atheism', 'augmented reality', 'autism', 'bacteria', 'beauty', 'bees', 'behavioral economics', 'big bang', 'big problems', 'biodiversity', 'bioethics', 'biology', 'biomechanics', 'biomimicry', 'bionics', 'biosphere', 'biotech', 'birds', 'blindness', 'blockchain', 'body language', 'book', 'books', 'botany', 'brain', 'bullying', 'business', 'cancer', 'capitalism', 'cars', 'cello', 'charter for compassion', 'chemistry', 'children', 'china', 'choice', 'cities', 'climate change', 'cloud', 'code', 'cognitive science', 'collaboration', 'comedy', 'communication', 'community', 'compassion', 'complexity', 'composing', 'computers', 'conducting', 'consciousness', 'conservation', 'consumerism', 'cooperation', 'coral reefs', 'coronavirus', 'corruption', 'cosmos', 'creativity', 'crime', 'criminal justice', 'crowdsourcing', 'cryptocurrency', 'culture', 'curiosity', 'dance', 'dark matter', 'data', 'death', 'decision-making', 'deextinction', 'demo', 'democracy', 'depression', 'design', 'development', 'dinosaurs', 'disability', 'disaster relief', 'discovery', 'disease', 'diversity', 'driverless cars', 'drones', 'ebola', 'ecology', 'economics', 'education', 'electricity', 'emotions', 'empathy', 'encryption', 'energy', 'engineering', 'entertainment', 'entrepreneur', 'environment', 'epidemiology', 'evil', 'evolution', 'evolutionary psychology', 'exercise', 'exoskeleton', 'exploration', 'extraterrestrial life', 'extreme sports', 'failure', 'faith', 'family', 'farming', 'fashion', 'fear', 'feminism', 'film', 'finance', 'fish', 'flight', 'food', 'forensics', 'friendship', 'fungi', 'funny', 'future', 'gaming', 'garden', 'gay', 'gender', 'gender equality', 'genetics', 'geology', 'glacier', 'global commons', 'global development', 'global issues', 'goal-setting', 'government', 'grammar', 'graphic design', 'green', 'guitar', 'guns', 'hack', 'happiness', 'health', 'health care', 'healthcare', 'hearing', 'heart health', 'history', 'homelessness', 'human body', 'human origins', 'human rights', 'humanity', 'humor', 'identity', 'illness', 'illusion', 'immigration', 'inclusion', 'india', 'indigenous peoples', 'industrial design', 'inequality', 'infrastructure', 'innovation', 'insects', 'intelligence', 'interface design', 'interview', 'introvert', 'invention', 'investment', 'iraq', 'jazz', 'journalism', 'justice system', 'language', 'law', 'leadership', 'library', 'life', 'literature', 'live music', 'love', 'machine learning', 'magic', 'manufacturing', 'map', 'marine biology', 'marketing', 'markets', 'materials', 'math', 'media', 'medical imaging', 'medical research', 'medicine', 'meditation', 'meme', 'memory', 'men', 'mental health', 'microbes', 'microbiology', 'microfinance', 'microsoft', 'military', 'mind', 'mindfulness', 'mining', 'mission blue', 'mobility', 'molecular biology', 'money', 'monkeys', 'morality', 'motivation', 'movies', 'museums', 'music', 'nanoscale', 'narcotics', 'natural disaster', 'natural resources', 'nature', 'neurology', 'neuroscience', 'news', 'nonviolence', 'novel', 'nuclear energy', 'nuclear weapons', 'obesity', 'oceans', 'oil', 'online video', 'open-source', 'opioids', 'origami', 'pain', 'painting', 'paleontology', 'pandemic', 'parenting', 'peace', 'performance', 'performance art', 'personal growth', 'personality', 'pharmaceuticals', 'philanthropy', 'philosophy', 'photography', 'physics', 'physiology', 'piano', 'plants', 'plastic', 'play', 'poetry', 'policy', 'politics', 'pollution', 'population', 'potential', 'poverty', 'prediction', 'pregnancy', 'presentation', 'primates', 'prison', 'privacy', 'product design', 'productivity', 'programming', 'prosthetics', 'protests', 'psychology', 'public health', 'public spaces', 'quantum physics', 'race', 'rap', 'refugees', 'relationships', 'religion', 'resources', 'rivers', 'robot', 'robots', 'rocket science', 'sanitation', 'science', 'science and art', 'science fiction', 'security', 'self', 'sex', 'sexual violence', 'shopping', 'sight', 'simplicity', 'singer', 'skateboarding', 'sleep', 'smell', 'social change', 'social media', 'society', 'sociology', 'software', 'solar energy', 'solar system', 'sound', 'space', 'speech', 'spoken word', 'sports', 'start-up', 'state-building', 'statistics', 'stigma', 'storytelling', 'street art', 'student', 'submarine', 'success', 'suicide', 'surveillance', 'sustainability', 'synthetic biology', 'teaching', 'technology', 'telecom', 'telescopes', 'television', 'terrorism', 'testing', 'theater', 'time', 'toy', 'trafficking', 'transportation', 'travel', 'trees', 'trust', 'typography', 'universe', 'urban', 'urban planning', 'violence', 'violin', 'virtual reality', 'virus', 'visualizations', 'vocals', 'vulnerability', 'war', 'water', 'weather', 'web', 'wikipedia', 'wind energy', 'women', 'women in business', 'work', 'work-life balance', 'world cultures', 'writing', 'wunderkind', 'youth']\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "data = useful_data\n",
    "\n",
    "# converting the text to \n",
    "all_topics = []\n",
    "for topics,i in zip(useful_data['topics'],range(len(useful_data['topics']))):\n",
    "    all_topics+=eval(topics)\n",
    "    useful_data.loc[i]['topics'] = eval(topics)\n",
    "\n",
    "unique_topics = sorted(list(set(all_topics)))\n",
    "print(unique_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>62678</td>\n",
       "      <td>['activism', 'data', 'technology', 'mental hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>62782</td>\n",
       "      <td>['TED-Ed', 'education', 'history', 'animation'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>62263</td>\n",
       "      <td>['society', 'law', 'policy', 'justice system',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>62784</td>\n",
       "      <td>['TED-Ed', 'education', 'animation', 'United S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>62794</td>\n",
       "      <td>['animals', 'TED-Ed', 'animation', 'oceans', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      talk_id                                             topics\n",
       "0           1  ['alternative energy', 'cars', 'climate change...\n",
       "1          92  ['Africa', 'Asia', 'Google', 'demo', 'economic...\n",
       "2           7  ['computers', 'entertainment', 'interface desi...\n",
       "3          53  ['MacArthur grant', 'activism', 'business', 'c...\n",
       "4          66  ['children', 'creativity', 'culture', 'dance',...\n",
       "...       ...                                                ...\n",
       "4000    62678  ['activism', 'data', 'technology', 'mental hea...\n",
       "4001    62782  ['TED-Ed', 'education', 'history', 'animation'...\n",
       "4002    62263  ['society', 'law', 'policy', 'justice system',...\n",
       "4003    62784  ['TED-Ed', 'education', 'animation', 'United S...\n",
       "4004    62794  ['animals', 'TED-Ed', 'animation', 'oceans', '...\n",
       "\n",
       "[4005 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8099379539489746),\n",
       " ('dog', 0.760945737361908),\n",
       " ('kitten', 0.7464985251426697),\n",
       " ('feline', 0.7326234579086304),\n",
       " ('beagle', 0.7150582671165466),\n",
       " ('puppy', 0.7075453400611877),\n",
       " ('pup', 0.6934291124343872),\n",
       " ('pet', 0.6891531348228455),\n",
       " ('felines', 0.6755931973457336),\n",
       " ('chihuahua', 0.6709762215614319)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = api.info()  # show info about available models/datasets\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use\n",
    "word2vec_model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function For Converting tags to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_to_word2vec_embeddings(dataframe, column_name, word2vec_model):\n",
    "\n",
    "    # Get the text from the specified column\n",
    "    tags = dataframe[column_name]\n",
    "    \n",
    "    # Initialize a list to store Word2Vec embeddings\n",
    "    embeddings = []\n",
    "\n",
    "    # Iterate through the texts and convert to Word2Vec embeddings\n",
    "    for tag_list in tags:\n",
    "        tokens = tag_list  # Tokenize the text\n",
    "        word_embeddings = [word2vec_model[token] for token in tokens if token in word2vec_model]\n",
    "        if word_embeddings:\n",
    "            # Calculate the paragraph embedding (average of word embeddings)\n",
    "            paragraph_embedding = np.mean(word_embeddings, axis=0)\n",
    "        else:\n",
    "            # Handle the case where there are no word embeddings\n",
    "            paragraph_embedding = np.zeros(word2vec_model.vector_size)\n",
    "        embeddings.append(paragraph_embedding)\n",
    "\n",
    "    # Create a new DataFrame with the embeddings\n",
    "    modified_dataframe = dataframe.copy()\n",
    "    modified_dataframe['tag_embeddings'] = embeddings\n",
    "\n",
    "    return modified_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>topics</th>\n",
       "      <th>tag_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>[-0.17534839, 0.10282389, -0.0007562747, 0.129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>[-0.17896906, 0.120670915, 0.010108304, 0.1194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>[-0.18247779, 0.11157528, -0.01706121, 0.15448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>[-0.179375, 0.09608236, -0.0026692708, 0.14162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>[-0.17675063, 0.101213045, -0.00961962, 0.1466...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                                             topics  \\\n",
       "0        1  ['alternative energy', 'cars', 'climate change...   \n",
       "1       92  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "2        7  ['computers', 'entertainment', 'interface desi...   \n",
       "3       53  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4       66  ['children', 'creativity', 'culture', 'dance',...   \n",
       "\n",
       "                                      tag_embeddings  \n",
       "0  [-0.17534839, 0.10282389, -0.0007562747, 0.129...  \n",
       "1  [-0.17896906, 0.120670915, 0.010108304, 0.1194...  \n",
       "2  [-0.18247779, 0.11157528, -0.01706121, 0.15448...  \n",
       "3  [-0.179375, 0.09608236, -0.0026692708, 0.14162...  \n",
       "4  [-0.17675063, 0.101213045, -0.00961962, 0.1466...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data = column_to_word2vec_embeddings(data, 'topics', word2vec_model)\n",
    "vectorized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      talk_id                                  recommended_talks\n",
      "0           1  {1374: 0.9984736, 22628: 0.9984503, 19756: 0.9...\n",
      "1          92  {140: 0.99801713, 620: 0.9971254, 2348: 0.9959...\n",
      "2           7  {400: 0.9983315, 1276: 0.99734735, 2310: 0.997...\n",
      "3          53  {2407: 0.99768436, 2855: 0.9970897, 2511: 0.99...\n",
      "4          66  {1734: 0.9962766, 815: 0.99602616, 36415: 0.99...\n",
      "...       ...                                                ...\n",
      "4000    62678  {2786: 0.9967842, 52190: 0.99572235, 41455: 0....\n",
      "4001    62782  {24271: 0.9979672, 58212: 0.9977772, 2734: 0.9...\n",
      "4002    62263  {2406: 0.9924404, 1145: 0.9917114, 50990: 0.99...\n",
      "4003    62784  {2697: 0.99713606, 2681: 0.9968118, 2521: 0.99...\n",
      "4004    62794  {59148: 0.99782175, 31779: 0.9976266, 23958: 0...\n",
      "\n",
      "[4005 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(vectorized_data['tag_embeddings'].tolist())\n",
    "\n",
    "# Function to get top similar talks for a given talk_id\n",
    "def get_top_similar_talks(talk_id, n=5):\n",
    "    # Get the index of the talk_id\n",
    "    index = data[data['talk_id'] == talk_id].index[0]\n",
    "\n",
    "    # Get similarity scores for the talk\n",
    "    sim_scores = list(enumerate(similarity_matrix[index]))\n",
    "\n",
    "    # Sort talks by similarity score (descending order)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top n similar talks (excluding itself)\n",
    "    top_similar_talks = sim_scores[1:n+1]\n",
    "\n",
    "    # Create a dictionary with talk_id and similarity score\n",
    "    result_dict = {data.iloc[talk[0]]['talk_id']: talk[1] for talk in top_similar_talks}\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Create a new column 'recommended_talks'\n",
    "vectorized_data['recommended_talks'] = data['talk_id'].apply(lambda x: get_top_similar_talks(x))\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(vectorized_data[['talk_id', 'recommended_talks']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1374: 0.9984736,\n",
       " 22628: 0.9984503,\n",
       " 19756: 0.997666,\n",
       " 60080: 0.99761516,\n",
       " 2633: 0.99745804}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data['recommended_talks'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ted_talks_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Talk : Averting the climate crisis\n",
      "Recommended Talks :\n",
      "The Earth is full\n",
      "How will we survive when the population hits 10 billion?\n",
      "A new way to remove CO2 from the atmosphere\n",
      "How we could change the planet's climate future\n",
      "We need nuclear power to solve climate change\n"
     ]
    }
   ],
   "source": [
    "query_talk_id = 1\n",
    "print(f\"Input Talk : {data['title'][data['talk_id'] == query_talk_id].values[0]}\")\n",
    "print(f\"Recommended Talks :\")\n",
    "for i in vectorized_data['recommended_talks'][vectorized_data['talk_id'] == query_talk_id].values[0]:\n",
    "    print(f\"{data['title'][data['talk_id'] == i].values[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEDLens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
